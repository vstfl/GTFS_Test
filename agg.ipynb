{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from glob import glob\n",
    "import os\n",
    "import seaborn as sb\n",
    "\n",
    "\n",
    "def get_dfs_from_glob(glob_str: str):\n",
    "    dfs = [\n",
    "        pl.read_csv(i, dtypes={'stopid': pl.Utf8, 'routeid': pl.Utf8})\n",
    "        for i in glob(glob_str)\n",
    "    ]\n",
    "    return pl.concat(dfs, how='vertical').unique()\n",
    "\n",
    "\n",
    "def load_raw_data():\n",
    "    \"\"\"\n",
    "    Load raw data from existing parquet file or from CSVs.\n",
    "    \"\"\"\n",
    "    df = (pl.read_parquet('raw.parquet')\n",
    "          if os.path.exists('raw.parquet')\n",
    "          else get_dfs_from_glob('raw_data/raw_trip_*').unique()\n",
    "          )\n",
    "    # Save memory by re-using strings for categorical data\n",
    "    return df.cast({\n",
    "        'period': pl.Categorical,\n",
    "        'routeid': pl.Categorical,\n",
    "        'stopid': pl.Categorical\n",
    "    })\n",
    "\n",
    "\n",
    "MAX_DELAY = 60*30\n",
    "\n",
    "\n",
    "def plot_stop(dfs: pl.DataFrame, stopid: str):\n",
    "    cats = (\n",
    "        dfs\n",
    "        .filter(pl.col('delay').abs() < MAX_DELAY)\n",
    "        .filter(pl.col('stopid') == stopid)\n",
    "        .group_by('id')\n",
    "        .all()\n",
    "        .select('id', 'delay', 'lastupdate')\n",
    "        .with_columns(pl.col('delay').list.len().alias('length'))\n",
    "        .explode('delay', 'lastupdate')\n",
    "        .sort('id', 'lastupdate')\n",
    "        .with_columns(pl.col('id').cast(pl.Utf8).cast(pl.Categorical))\n",
    "    )\n",
    "    sb.scatterplot(cats, x='lastupdate', y='delay', hue='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = pl.read_csv(\n",
    "    '/home/chrlz/dox/dl/ETS_Bus_Schedule_GTFS_Data_Feed_-_Stops_20240216.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dfs = load_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading from the CSVs take like 30 seconds!!!\n",
    "# Save into a more compact form for easier retrieval later\n",
    "raw_dfs.write_parquet('raw.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we know that all trip id is unique for a single day, no need to worry about overlaps\n",
    "\n",
    "Average delay in a stop every 3 minutes 10 recordings of a bus\n",
    "\n",
    "AM: 7am-9am\n",
    "PM: 4pm-7pm\n",
    "OFF: 5am-7am, 9am-4-pm, 7pm-10pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate all data\n",
    "MAX_DELAY = 60 * 20\n",
    "delay = pl.col('delay')\n",
    "aggregated = (\n",
    "    raw_dfs\n",
    "    .with_columns(delay.abs())\n",
    "    .with_columns(\n",
    "        pl.from_epoch('lastupdate', time_unit='s')\n",
    "        # MST\n",
    "        .dt.offset_by('-7h')\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col('lastupdate').dt.date().alias('date'),\n",
    "        pl.col('lastupdate').dt.weekday().alias('day'),\n",
    "    )\n",
    "    # Get only the weekdays (6 = saturday, 7 = sunday)\n",
    "    .filter(pl.col('day') < 6)\n",
    "    .sort('lastupdate')\n",
    "    .group_by('id', 'stopid', 'date', 'period')\n",
    "    .agg(\n",
    "        pl.col('routeid').first(),\n",
    "        pl.col('lastupdate').max(),\n",
    "        delay.max().alias('maxdelay'),\n",
    "        delay.mean().alias('meandelay'),\n",
    "        delay.median().alias('mediandelay'),\n",
    "        delay.std().alias('stddelay'),\n",
    "        delay\n",
    "    )\n",
    "    .with_columns(pl.col('date').dt.weekday().alias('day'))\n",
    "    .with_columns(pl.col('lastupdate').dt.hour().alias('hour'))\n",
    "    # Just remove trips that are above MAX_DELAY\n",
    "    .filter(pl.col('meandelay') < MAX_DELAY)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_group(df: pl.DataFrame, *groups: str):\n",
    "    return (\n",
    "        df.group_by(groups)\n",
    "        .agg(\n",
    "            pl.col('meandelay').mean().alias('avgdelay'),\n",
    "            pl.col('meandelay').max().alias('maxdelay'),\n",
    "            pl.col('lastupdate')\n",
    "        )\n",
    "        .sort(groups)\n",
    "    )\n",
    "\n",
    "\n",
    "# 1. Map delay average over week\n",
    "mean_stop = aggregated.pipe(agg_group, 'stopid')\n",
    "\n",
    "# 2. Over week by day\n",
    "# TODO: Filter by PEAK, OFF, and DAY\n",
    "by_day_all = aggregated.pipe(agg_group, 'day', 'period')\n",
    "by_day_peak = (\n",
    "    aggregated\n",
    "    .filter(pl.col('period') != 'OFF')\n",
    "    .pipe(agg_group, 'day', 'period')\n",
    ")\n",
    "by_day_off = (\n",
    "    aggregated\n",
    "    .filter(pl.col('period') == 'OFF')\n",
    "    .pipe(agg_group, 'day', 'period')\n",
    ")\n",
    "\n",
    "\n",
    "# 3. Over day by hour\n",
    "by_hour = aggregated.pipe(agg_group, 'day', 'hour')\n",
    "\n",
    "\n",
    "def select_stop(df: pl.DataFrame, stopid: str):\n",
    "    return (\n",
    "        df.filter(pl.col('stopid') == stopid)\n",
    "        .pipe(agg_group, 'routeid')\n",
    "        .drop('lastupdate')\n",
    "    )\n",
    "\n",
    "def select_stop_and_route(df: pl.DataFrame, stopid: str, routeid: str):\n",
    "    return (\n",
    "        df.filter(\n",
    "            (pl.col('stopid') == stopid) & \n",
    "            (pl.col('routeid') == routeid)\n",
    "        )\n",
    "        .pipe(agg_group, 'day', 'hour')\n",
    "        .drop('lastupdate')\n",
    "    )\n",
    "\n",
    "\n",
    "# TODO: Select route\n",
    "# 4. Time series graph of route by hour by day\n",
    "\n",
    "\n",
    "highest_delay_stops = (\n",
    "    mean_stop\n",
    "    .group_by('stopid')\n",
    "    .agg(pl.col('avgdelay').max())\n",
    "    .sort('avgdelay', descending=True)\n",
    "    .select('stopid')\n",
    "    .head(100)\n",
    "    .unique()\n",
    "    .join(aggregated, on='stopid')\n",
    ")\n",
    "routes_on_highest_delay_stops = (\n",
    "    highest_delay_stops\n",
    "    .select('routeid')\n",
    "    .unique()\n",
    "    .join(aggregated, on='routeid')\n",
    ")\n",
    "agg_routes_on_highest_delay = (\n",
    "    routes_on_highest_delay_stops\n",
    "    .pipe(agg_group, 'routeid')\n",
    "    .drop('lastupdate')\n",
    ")\n",
    "\n",
    "def plot_by_route(df: pl.DataFrame):\n",
    "    tidy = (\n",
    "        agg_routes_on_highest_delay\n",
    "        .sort('routeid')\n",
    "        .melt(id_vars='routeid')\n",
    "        .sort('routeid')\n",
    "    )\n",
    "    xticks = tidy['routeid']\n",
    "    xticks_unique = tidy['routeid'].unique()\n",
    "    ax = sb.barplot(\n",
    "        data=tidy,\n",
    "        x='routeid',\n",
    "        y='value',\n",
    "        hue='variable',\n",
    "        width=1,\n",
    "        order=xticks,\n",
    "    )\n",
    "    ax.set_xticks(ax.get_xticks(), xticks_unique, rotation=90)\n",
    "\n",
    "\n",
    "# 5. Mapping delay propagations within a route\n",
    "# 6. TODO\n",
    "\n",
    "def plot_stop_and_route(df: pl.DataFrame, stop: str, route: str):\n",
    "    days= pl.DataFrame({\n",
    "        \"day\": [*range(1, 6)],\n",
    "        \"letter\": ['M', 'T', 'W', 'R', 'F'],\n",
    "    }, schema={\"day\": pl.Int8, 'letter': pl.Categorical})\n",
    "    by_day_by_hour_for_stop = (\n",
    "        select_stop_and_route(df,stop,route)\n",
    "        .join(days, on='day')\n",
    "        .drop('day')\n",
    "        .rename({'letter': 'day'})\n",
    "    )\n",
    "\n",
    "    ax = sb.barplot(by_day_by_hour_for_stop, x='hour', y='avgdelay', hue='day')\n",
    "    ax.set_title(f'Average delay for route {route} stop {stop}')\n",
    "\n",
    "plot_stop_and_route(aggregated, \"2260\", \"637\")\n",
    "# select_stop(aggregated, \"2260\")\n",
    "\n",
    "# sb.barplot(by_day_by_hour_for_stop, x='hour', y='maxdelay')\n",
    "\n",
    "\n",
    "highest_delay_stops['stopid'].unique()\n",
    "# select_stop(aggregated, \"2260\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some exploration of the `trips.json` file which DOES contain coordinates of the\n",
    "trip\n",
    "\n",
    "From initial observation of the data, each trip may have a unique path, even for\n",
    "the same route (e.g. shorter route for off-peak hours, my bus route home was\n",
    "like that at one point)\n",
    "\n",
    "Other assumptions:\n",
    "- There is only one type of geometry line: MultiLineString\n",
    "- The actual coordinates are wrapped inside another JSON array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trips_df():\n",
    "    if os.path.exists('data/trips.parquet'):\n",
    "        return pl.read_parquet('data/trips.parquet')\n",
    "\n",
    "    import json\n",
    "    return (\n",
    "        pl.DataFrame(json.load(open('data/trips.json')))\n",
    "        # Trim JSON data according to the assumptions \n",
    "        .with_columns(pl.col('geometry_line').struct.field('coordinates'))\n",
    "        .with_columns(pl.col('coordinates').list.get(0))\n",
    "        .drop('geometry_line')\n",
    "    )\n",
    "trips = load_trips_df()\n",
    "if not os.path.exists('data/trips.parquet'):\n",
    "    trips.write_parquet('data/trips.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many counts should we deem useful for visualization of data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set_fmt_table_cell_list_len(100)\n",
    "aggregated['routeid']\n",
    "# 1_250_916"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
