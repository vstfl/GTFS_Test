{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import seaborn as sb\n",
    "import gtfs_delay_analysis as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = pl.read_csv(\n",
    "    '/home/chrlz/dox/dl/ETS_Bus_Schedule_GTFS_Data_Feed_-_Stops_20240216.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated = da.load_aggregate_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we know that all trip id is unique for a single day, no need to worry about overlaps\n",
    "\n",
    "Average delay in a stop every 3 minutes 10 recordings of a bus\n",
    "\n",
    "AM: 7am-9am\n",
    "PM: 4pm-7pm\n",
    "OFF: 5am-7am, 9am-4-pm, 7pm-10pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Map delay average over week\n",
    "mean_stop = aggregated.pipe(da.agg_group, 'stopid')\n",
    "\n",
    "# 2. Over week by day\n",
    "# TODO: Filter by PEAK, OFF, and DAY\n",
    "\n",
    "def pivot_day(df: pl.DataFrame):\n",
    "    def get_day(d: str):\n",
    "        if 'day' not in d:\n",
    "            return d\n",
    "        col, _, d = d.split('_')\n",
    "        days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "        return f'{days[int(d)-1]}_{col[:3]}'\n",
    "    return (\n",
    "        df.select('day', 'hour', 'avgdelay', 'stddelay')\n",
    "        .pivot(values=['avgdelay', 'stddelay'], index='hour', columns='day')\n",
    "        .rename(get_day)\n",
    "    )\n",
    "\n",
    "def by_day(df: pl.DataFrame):\n",
    "    by_day_all = df.pipe(da.agg_group, 'day')\n",
    "    by_day_peak = (\n",
    "        df\n",
    "        .filter(pl.col('period') != 'OFF')\n",
    "        .pipe(da.agg_group, 'day')\n",
    "    )\n",
    "    by_day_off = (\n",
    "        df\n",
    "        .filter(pl.col('period') == 'OFF')\n",
    "        .pipe(da.agg_group, 'day')\n",
    "    )\n",
    "\n",
    "    def get(df: pl.DataFrame, prefix: str):\n",
    "        return df.select(\n",
    "            'day',\n",
    "            pl.col('avgdelay').alias(f'{prefix}_avg'),\n",
    "            pl.col('stddelay').alias(f'{prefix}_std'),\n",
    "        )\n",
    "    g_day = (\n",
    "        by_day_all.pipe(get, 'all')\n",
    "        .join(by_day_peak.pipe(get, 'peak'), on='day', how='left')\n",
    "        .join(by_day_off.pipe(get, 'off'), on='day', how='left')\n",
    "    )\n",
    "\n",
    "    # 3. Over day by hour\n",
    "    by_hour = df.pipe(da.agg_group, 'day', 'hour')\n",
    "    return g_day, by_hour, by_hour.pipe(pivot_day)\n",
    "\n",
    "\n",
    "network_by_day, by_hour, by_hour_pivot = by_day(aggregated)\n",
    "\n",
    "# TODO: Select route\n",
    "# 4. Time series graph of route by hour by day\n",
    "\n",
    "\n",
    "highest_delay_stops = (\n",
    "    mean_stop\n",
    "    .group_by('stopid')\n",
    "    .agg(pl.col('avgdelay').max())\n",
    "    .sort('avgdelay', descending=True)\n",
    "    .select('stopid')\n",
    "    .head(100)\n",
    "    .unique()\n",
    "    .join(aggregated, on='stopid')\n",
    ")\n",
    "routes_on_highest_delay_stops = (\n",
    "    highest_delay_stops\n",
    "    .select('routeid')\n",
    "    .unique()\n",
    "    .join(aggregated, on='routeid')\n",
    ")\n",
    "agg_routes_on_highest_delay = (\n",
    "    routes_on_highest_delay_stops\n",
    "    .pipe(da.agg_group, 'routeid')\n",
    "    .drop('lastupdate')\n",
    ")\n",
    "\n",
    "\n",
    "def plot_cols(df: pl.DataFrame, key: str):\n",
    "    tidy = df.melt(id_vars=key).sort(key)\n",
    "    xticks = tidy[key]\n",
    "    ax = sb.barplot(\n",
    "        data=tidy,\n",
    "        x=key,\n",
    "        y='value',\n",
    "        hue='variable',\n",
    "        width=1,\n",
    "        order=xticks,\n",
    "    )\n",
    "    return tidy, ax\n",
    "\n",
    "\n",
    "def plot_by_route(df: pl.DataFrame):\n",
    "    tidy, ax = plot_cols(df, 'routeid')\n",
    "    xticks_unique = tidy['routeid'].unique()\n",
    "    ax.set_xticks(ax.get_xticks(), xticks_unique, rotation=90)\n",
    "\n",
    "\n",
    "# 5. Mapping delay propagations within a route\n",
    "# 6. TODO\n",
    "\n",
    "def plot_stop_and_route(df: pl.DataFrame, stop: str, route: str):\n",
    "    days = pl.DataFrame({\n",
    "        \"day\": [*range(1, 6)],\n",
    "        \"letter\": ['M', 'T', 'W', 'R', 'F'],\n",
    "    }, schema={\"day\": pl.Int8, 'letter': pl.Categorical})\n",
    "    by_day_by_hour_for_stop = (\n",
    "        da.select_stop_and_route(df, stop, route)\n",
    "        .join(days, on='day')\n",
    "        .drop('day')\n",
    "        .rename({'letter': 'day'})\n",
    "    )\n",
    "\n",
    "    ax = sb.barplot(by_day_by_hour_for_stop, x='hour', y='avgdelay', hue='day')\n",
    "    ax.set_title(f'Average delay for route {route} stop {stop}')\n",
    "    return by_day_by_hour_for_stop\n",
    "\n",
    "\n",
    "# select_stop(aggregated, \"2260\")\n",
    "\n",
    "# sb.barplot(by_day_by_hour_for_stop, x='hour', y='maxdelay')\n",
    "\n",
    "\n",
    "# highest_delay_stops.select('stopid').unique()\n",
    "\n",
    "# plot_stop_and_route(aggregated, \"2260\", \"637\")\n",
    "# da.select_stop(aggregated, \"2260\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_stop_and_route(agg: pl.DataFrame, stopid: str, routeid: str):\n",
    "    g_day, g_hour, g_hour_pivot = (\n",
    "        agg\n",
    "        .filter(\n",
    "            (pl.col('stopid') == stopid)\n",
    "            & (pl.col('routeid') == routeid)\n",
    "        )\n",
    "        .pipe(by_day)\n",
    "    )\n",
    "\n",
    "    g_hour.drop('lastupdate').write_csv(f'{stopid}-{routeid}-by-hour.csv')\n",
    "    g_hour_pivot.write_csv(f'{stopid}-{routeid}-by-hour-pivot.csv')\n",
    "    g_day.write_csv(f'{stopid}-{routeid}-by-day.csv')\n",
    "    return g_day, g_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, bd = aggregated.pipe(filter_by_stop_and_route, '2260', '004')\n",
    "_, bd = aggregated.pipe(filter_by_stop_and_route, '2260', '637')\n",
    "m637 = aggregated.filter(\n",
    "    pl.col('routeid').__eq__('637').and_(\n",
    "        pl.col('stopid').__eq__('2260')\n",
    "    )\n",
    ")['meandelay'].mean()\n",
    "\n",
    "m004 =aggregated.filter(\n",
    "    pl.col('routeid').__eq__('004').and_(\n",
    "        pl.col('stopid').__eq__('2260')\n",
    "    )\n",
    ")['meandelay'].mean()\n",
    "m637, m004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dfs = da.load_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dfs.filter(\n",
    "    pl.col('routeid').__eq__('637').and_(\n",
    "        pl.col('stopid').__eq__('2260')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated.filter( (pl.col('stopid') == \"2260\")\n",
    "    & (pl.col('routeid') == \"637\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*_, network_pivot = aggregated.pipe(by_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated.filter(pl.col('stopid') == '1899').group_by('routeid').agg(\n",
    "    pl.col('meandelay').mean().alias('avgdelay'),\n",
    "    pl.col('maxdelay').max().alias('maxdelay'),\n",
    "    pl.col('count').sum()\n",
    ").write_csv('1899-by-route.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_stop.pipe(da.add_coords, stops).drop(\n",
    "    'lastupdate').write_csv('mean-stop.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_by_day.drop('lastupdate').write_csv('network-by-day.csv')\n",
    "by_hour.drop('lastupdate').write_csv('network-by-day-by-hour.csv')\n",
    "# by_hour.drop('lastupdate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot_cols(df, 'day') and None\n",
    "\n",
    "# plot_cols(by_hour.select('hour', 'day', 'avgdelay'), 'hour') and None\n",
    "\n",
    "# by_hour\n",
    "\n",
    "to_plot = by_hour.select('day', 'hour', 'avgdelay')\n",
    "ax = sb.lineplot(to_plot, x='hour', y='avgdelay', hue='day')\n",
    "ax.set_xticks([*range(5, 23)]) and None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    mean_stop.drop('lastupdate')\n",
    "    .pipe(da.add_coords, stops)\n",
    "    .write_csv('mean-stop.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mean_stop) - len(mean_stop.filter(pl.col('numtrips') > 200))\n",
    "# len(mean_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some exploration of the `trips.json` file which DOES contain coordinates of the\n",
    "trip\n",
    "\n",
    "From initial observation of the data, each trip may have a unique path, even for\n",
    "the same route (e.g. shorter route for off-peak hours, my bus route home was\n",
    "like that at one point)\n",
    "\n",
    "Other assumptions:\n",
    "- There is only one type of geometry line: MultiLineString\n",
    "- The actual coordinates are wrapped inside another JSON array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = da.load_trips_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set_fmt_str_lengths(1000)\n",
    "trips.sort('route_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopolars as gp\n",
    "gp.GeoDataFrame(mean_stop.pipe(da.add_coords, stops)).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many counts should we deem useful for visualization of data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set_fmt_table_cell_list_len(100)\n",
    "aggregated['routeid']\n",
    "# 1_250_916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_stop_and_route(aggregated, '1899', '560')\n",
    "# plot_stop_and_route(aggregated, '1899', '413')\n",
    "# plot_stop_and_route(aggregated, '5281', '002')\n",
    "# plot_stop_and_route(aggregated, '5281', '004')\n",
    "\n",
    "aggregated.filter(\n",
    "    (pl.col('stopid') == '2260')\n",
    "    # & (pl.col('routeid') == '904')\n",
    ").group_by('routeid').agg(\n",
    "    pl.col('count').sum(),\n",
    "    pl.col('meandelay').sum(),\n",
    ")\n",
    "# 25529677\n",
    "\n",
    "da.select_stop(aggregated, '2260')\n",
    "\n",
    "# plot_stop_and_route(aggregated, '2260', '004')\n",
    "plot_stop_and_route(aggregated, '2260', '637')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = da.trips.load_parsed_shapes_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = da.trips.load_trips_without_shapes_df()\n",
    "shapes = da.trips.load_str_shapes_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "25536739"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.filter(pl.col('trip_id') == 25536739).join(\n",
    "    shapes,\n",
    "    on='shape_id'\n",
    ").select('route_id', 'shape_id').unique().join(\n",
    "    shapes, on='shape_id'\n",
    ").write_csv(f'004-{25536739}-shapes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find trip with highest delay on Tuesday for route 560\n",
    "aggregated.filter(\n",
    "    (pl.col('routeid') == \"560\")\n",
    "    & (pl.col('day') == 2)\n",
    ").group_by('id').agg(\n",
    "    pl.col('meandelay').max()\n",
    ").sort('meandelay', descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all points for that trip\n",
    "def filter_by_trip(id: int, day: int):\n",
    "    df = aggregated.filter(\n",
    "        (pl.col('id') == id) &\n",
    "        (pl.col('day') == day)\n",
    "    ).pipe(da.add_coords, stops).sort('meandelay').drop('delay')\n",
    "    df.write_csv(f'{id}-{day}-stops.csv')\n",
    "    return df\n",
    "\n",
    "\n",
    "# filter_by_trip(25527827, 2)\n",
    "# filter_by_trip(25527777, 2)\n",
    "# filter_by_trip(25527796, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_delayed_trips = [*aggregated.filter(pl.col('routeid') == \"637\").group_by('id', 'date', 'day').agg(\n",
    "    pl.col('meandelay').max(),\n",
    ").sort('meandelay', descending=True).head(3).select('id', 'day').iter_rows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_delayed_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tripid, day in most_delayed_trips:\n",
    "    filter_by_trip(tripid, day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dfs = da.load_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_stop.filter(pl.col('count') > 20).sort('avgdelay', descending=True)\n",
    "\n",
    "# pl.Config\n",
    "\n",
    "more_than_one_route = (\n",
    "    aggregated\n",
    "    .group_by('stopid')\n",
    "    .agg(pl.col('routeid').unique())\n",
    "    .with_columns(pl.col('routeid').list.len())\n",
    "    .filter(pl.col('routeid') > 1)\n",
    "    .select('stopid')\n",
    ")\n",
    "\n",
    "# aggregated.join(more_than_one_route, on='stopid')\n",
    "mean_stop.join(more_than_one_route, on='stopid').sort(\n",
    "    'avgdelay', descending=True)\n",
    "\n",
    "(\n",
    "    aggregated.filter(pl.col('stopid') == \"2260\")\n",
    "    ['routeid'].unique()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
