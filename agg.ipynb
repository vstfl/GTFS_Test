{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "import seaborn as sb\n",
        "import gtfs_delay_analysis as da"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import importlib\n",
        "importlib.reload(da)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "aggregated = da.load_aggregate_data()\n",
        "stops = pl.read_csv(\n",
        "    '/home/chrlz/dox/dl/ETS_Bus_Schedule_GTFS_Data_Feed_-_Stops_20240216.csv')\n",
        "raw_dfs = da.load_raw_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Some exploration of the `trips.json` file which DOES contain coordinates of the\n",
        "trip\n",
        "\n",
        "From initial observation of the data, each trip may have a unique path, even for\n",
        "the same route (e.g. shorter route for off-peak hours, my bus route home was\n",
        "like that at one point)\n",
        "\n",
        "Other assumptions:\n",
        "\n",
        "- There is only one type of geometry line: MultiLineString\n",
        "- The actual coordinates are wrapped inside another JSON array\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trips = da.trips.load_trips_without_shapes_df()\n",
        "str_shapes = da.trips.load_str_shapes_df()\n",
        "shapes = da.trips.load_parsed_shapes_df()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pl.Config.set_fmt_str_lengths(1000)\n",
        "trips.sort('route_id')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "How many counts should we deem useful for visualization of data?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pl.Config.set_fmt_table_cell_list_len(100)\n",
        "aggregated['routeid']\n",
        "# 1_250_916"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rev_1 = (\n",
        "    aggregated.join(\n",
        "        trips.select('trip_headsign', 'shape_id', 'route_id', id='trip_id'),\n",
        "        on='id',\n",
        "    )\n",
        "    .group_by('route_id', 'trip_headsign', 'shape_id').agg(\n",
        "        pl.col('meandelay').mean(),\n",
        "        pl.col('count').sum(),\n",
        "        pl.col('id').n_unique()\n",
        "    )\n",
        "    .sort('meandelay', descending=True)\n",
        "    .filter(pl.col('id') > 30)\n",
        "\n",
        ")\n",
        "# rev_1.write_csv('avg-delay-by-trip-headsign.csv')\n",
        "\"\"\"\n",
        "1. Join `trips` to `aggregated` to new dataframe, only adding `trip_headsign` column. \n",
        "\n",
        " *THEN* GroupBy(`trip_headsign`) + Aggregate(average the delay). \n",
        "Drop all columns except the Heading, Aggregated Average Delay\n",
        "\n",
        "-> Sort by descending meandelay\n",
        "\"\"\"\n",
        "\n",
        "max_trip_headsign = rev_1[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rev_2_1 = (\n",
        "    aggregated.join(\n",
        "        trips.select('trip_headsign', 'shape_id', 'route_id', id='trip_id'),\n",
        "        on='id',\n",
        "    )\n",
        "    .filter(\n",
        "        (pl.col('routeid') == max_trip_headsign['route_id'][0]) &\n",
        "        (pl.col('shape_id') == max_trip_headsign['shape_id'][0]) &\n",
        "        (pl.col('trip_headsign') == max_trip_headsign['trip_headsign'][0])\n",
        "    )\n",
        "    .group_by('id')\n",
        "    .agg(\n",
        "        pl.col('route_id').first(),\n",
        "        pl.col('trip_headsign').first(),\n",
        "        pl.col('meandelay').mean(),\n",
        "        pl.col('count').sum(),\n",
        "    )\n",
        "    .sort('meandelay', 'route_id', descending=True)\n",
        "    # .write_csv('avg-by-trip-id-508-Meadows.csv')\n",
        ")\n",
        "\"\"\"\n",
        "2.1 Based on a given **Heading**: Select all associated rows, GroupBy(TripId) + \n",
        "Aggregate(Average the delay). \n",
        "-> Sort by descending meandelay. Select highest meandelay of the few. \n",
        "(tripid is the identifier)\n",
        "\"\"\"\n",
        "None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "def join_stops(df: pl.DataFrame, stops: pl.DataFrame):\n",
        "    return (\n",
        "        df.with_columns(pl.col('stopid').cast(pl.Utf8))\n",
        "        .join(stops, left_on='stopid', right_on='stop_id')\n",
        "    )\n",
        "\n",
        "\n",
        "def make_sequence(\n",
        "    df: pl.DataFrame,\n",
        "    trip_id: Optional[int] = None,\n",
        "    shape_id: Optional[str] = None,\n",
        "    trips: Optional[pl.DataFrame] = None,\n",
        "    shapes: Optional[pl.DataFrame] = None,\n",
        "):\n",
        "    trips = trips if trips is not None else  da.trips.load_trips_without_shapes_df()\n",
        "    shapes = shapes if shapes is not None else da.trips.load_parsed_shapes_df()\n",
        "    by_stop = df.group_by('stopid').agg(\n",
        "        pl.col('meandelay').mean(),\n",
        "        pl.col('stop_lon').first(),\n",
        "        pl.col('stop_lat').first(),\n",
        "        pl.col('routeid').first().cast(pl.Utf8),\n",
        "    )\n",
        "    pred = (\n",
        "        pl.col('trip_id').eq(trip_id) if trip_id\n",
        "        else pl.col('shape_id').eq(shape_id) if shape_id\n",
        "        else True)\n",
        "    trip_points = (\n",
        "        trips\n",
        "        .filter(pred)\n",
        "        .join(shapes, on='shape_id')\n",
        "        .unique('shape_id')\n",
        "        .explode('geometry_line')\n",
        "        .unique('geometry_line', keep='first', maintain_order=True)\n",
        "        .with_row_index()\n",
        "    )\n",
        "    return (\n",
        "        trip_points.join(\n",
        "            by_stop,\n",
        "            left_on='route_id',\n",
        "            right_on='routeid',\n",
        "        )\n",
        "        .with_columns(\n",
        "            pl.col('geometry_line').struct.field(\n",
        "                'lon').sub(pl.col('stop_lon')),\n",
        "            pl.col('geometry_line').struct.field(\n",
        "                'lat').sub(pl.col('stop_lat')),\n",
        "        )\n",
        "        # Get euclidean distance\n",
        "        .with_columns(\n",
        "            pl.col('lon').pow(2).add(pl.col('lat').pow(2))\n",
        "            .sqrt().alias('euclidean')\n",
        "        )\n",
        "        # Get the minimum euclidean distance for a stop\n",
        "        .filter(pl.col('euclidean').eq(pl.col('euclidean').min().over('stopid')))\n",
        "        # Re-create index\n",
        "        .sort('index')\n",
        "        .drop('index')\n",
        "        .with_row_index()\n",
        "        .select([\n",
        "            'index',\n",
        "            'route_id',\n",
        "            'trip_headsign',\n",
        "            'stopid',\n",
        "            'shape_id',\n",
        "            'meandelay',\n",
        "            'stop_lon',\n",
        "            'stop_lat',\n",
        "        ])\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_trip = 25536592\n",
        "agg_points = (\n",
        "    aggregated\n",
        "    .filter(pl.col('id').eq(selected_trip))\n",
        "    .pipe(join_stops, stops)\n",
        ")\n",
        "rev_2_2 = make_sequence(agg_points, trip_id=selected_trip)\n",
        "\"\"\"\n",
        "2.2 Based on the selected `trip_headsign` **AND** `trip_id`: Select all the \n",
        "associated rows, join co-ordinates to StopId, join sequence #\n",
        "\"\"\"\n",
        "# rev_2_2.write_csv(f'rev-2.2-508-meadows-{selected_trip}-stops.csv')\n",
        "\n",
        "selected_shape = \"508-1-East\"\n",
        "all_trips_for_route=(\n",
        "    trips\n",
        "    .filter(pl.col('shape_id').eq(selected_shape))\n",
        "    .select('trip_id', 'shape_id')\n",
        ")\n",
        "agg_points = (\n",
        "    aggregated\n",
        "    .join(all_trips_for_route, left_on='id', right_on='trip_id')\n",
        "    .pipe(join_stops, stops)\n",
        ")\n",
        "rev_2_3 = make_sequence(agg_points, shape_id=selected_shape)\n",
        "\"\"\"\n",
        "2.3 Based on the selected **Heading**: Select all the associated rows, \n",
        "GroupBy(Sequence #) + Aggregate(Average the delay) \n",
        "\n",
        "-> Output df: **Sequence # | AverageAverageDelay**\n",
        "\"\"\"\n",
        "# rev_2_3.write_csv(f'rev-2.3-{selected_shape}-stops.csv')\n",
        "None\n",
        "rev_2_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_points = aggregated.join(\n",
        "    trips.select('trip_id', 'shape_id').unique(),\n",
        "    left_on='id',\n",
        "    right_on='trip_id',\n",
        ").pipe(join_stops, stops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "seq_508 = pl.concat([\n",
        "    make_sequence(agg_points, t, trips=trips, shapes=shapes)\n",
        "    .with_columns(trip_id=t)\n",
        "    for t in all_trips_for_route['trip_id']\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "network_so_bad = pl.concat([\n",
        "    make_sequence(all_points, t, trips=trips, shapes=shapes)\n",
        "    .with_columns(trip_id=t)\n",
        "    for t in tqdm.tqdm(all_points['id'].unique())\n",
        "])\n",
        "# 100%|██████████| 12987/12987 [10:23<00:00, 20.83it/s]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "network_so_bad.write_parquet('sequence.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "network_so_bad.write_csv('sequence.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "network_so_bad = pl.read_parquet('sequence.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "network_so_bad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "network_so_bad['shape_id'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "network_so_bad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "network_seq =make_sequence(\n",
        "aggregated.join(trips.select('trip_id', 'shape_id'), left_on='id', right_on='trip_id').pipe(join_stops, stops)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "seq_508.write_csv('seq-508-meadows.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rev_2_3_off = make_sequence(agg_points.filter(pl.col('period').eq('OFF')), shape_id=selected_shape)\n",
        "rev_2_3_peak = make_sequence(agg_points.filter(pl.col('period').ne('OFF')), shape_id=selected_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# ddelay_rev_2_3_off.write_csv('508-Meadows-Delay-OFF-PEAK.csv')\n",
        "# ddelay_rev_2_3_peak.write_csv('508-Meadows-Delay-PEAK.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from gtfs_delay_analysis.ddelay import get_ddelay, plot_ddelay, plot_mean\n",
        "ddelay_rev_2_2 = rev_2_2.with_columns(trip_id=selected_trip).pipe(get_ddelay)\n",
        "ddelay_rev_2_3 = rev_2_3.with_columns(trip_id=0).pipe(get_ddelay)\n",
        "\n",
        "ddelay_rev_2_3_off = rev_2_3_off.with_columns(\n",
        "    trip_id=selected_trip).pipe(get_ddelay)\n",
        "ddelay_rev_2_3_peak = rev_2_3_peak.with_columns(trip_id=0).pipe(get_ddelay)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from gtfs_delay_analysis.ddelay import get_ddelay, plot_ddelay, plot_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_ddelay = (\n",
        "network_so_bad\n",
        ".pipe(get_ddelay)\n",
        ".with_columns( pl.col('line').str.split('-'))\n",
        ".with_columns(\n",
        "    pl.col('line').list.get(0).alias('a'),\n",
        "    pl.col('line').list.get(1).alias('b'),\n",
        ")\n",
        ".drop('line')\n",
        ".join(stops.select('stop_id', a_lon='stop_lon', a_lat='stop_lat'), left_on='a', right_on='stop_id')\n",
        ".join(stops.select('stop_id', b_lon='stop_lon', b_lat='stop_lat'), left_on='b', right_on='stop_id')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_ddelay.write_parquet('all_ddelay.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with_shape = network_so_bad.pipe(get_ddelay).with_columns(\n",
        "    pl.col('trip_id').cast(pl.Int64)\n",
        ").join(trips.select('trip_id', 'shape_id'), on='trip_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with_shape.join(shapes, on='shape_id').drop('shape_id', 'line_length', 'line')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_ddelay(seq_508).write_csv('seq-508-ddelay.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_ddelay(ddelay_rev_2_3_peak, 'PEAK')\n",
        "plot_ddelay(ddelay_rev_2_3_off, 'OFF')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_ddelay(ddelay_rev_2_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_mean(rev_2_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pl.Config.set_tbl_rows(100)\n",
        "rev_2_2.with_columns(\n",
        "    pl.col('meandelay').diff().alias('ddelay')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trips.write_csv('trips-new.csv')\n",
        "shapes.write_csv('shapes-new.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "aggregated.filter(pl.col('id') == 25536770).sort('lastupdate')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_dfs = da.load_raw_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trips.filter(pl.col('route_id') == \"004\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
