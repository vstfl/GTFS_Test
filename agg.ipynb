{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "import seaborn as sb\n",
        "import gtfs_delay_analysis as da"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import importlib\n",
        "importlib.reload(da)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stops = pl.read_csv(\n",
        "    '/home/chrlz/dox/dl/ETS_Bus_Schedule_GTFS_Data_Feed_-_Stops_20240216.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "aggregated = da.load_aggregate_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So we know that all trip id is unique for a single day, no need to worry about overlaps\n",
        "\n",
        "Average delay in a stop every 3 minutes 10 recordings of a bus\n",
        "\n",
        "AM: 7am-9am\n",
        "PM: 4pm-7pm\n",
        "OFF: 5am-7am, 9am-4-pm, 7pm-10pm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Map delay average over week\n",
        "mean_stop = aggregated.pipe(da.agg_group, 'stopid')\n",
        "\n",
        "# 2. Over week by day\n",
        "# TODO: Filter by PEAK, OFF, and DAY\n",
        "\n",
        "\n",
        "def pivot_day(df: pl.DataFrame):\n",
        "    def get_day(d: str):\n",
        "        if 'day' not in d:\n",
        "            return d\n",
        "        col, _, d = d.split('_')\n",
        "        days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
        "        return f'{days[int(d)-1]}_{col[:3]}'\n",
        "    return (\n",
        "        df.select('day', 'hour', 'avgdelay', 'stddelay')\n",
        "        .pivot(values=['avgdelay', 'stddelay'], index='hour', columns='day')\n",
        "        .rename(get_day)\n",
        "    )\n",
        "\n",
        "\n",
        "def by_day(df: pl.DataFrame):\n",
        "    by_day_all = df.pipe(da.agg_group, 'day')\n",
        "    by_day_peak = (\n",
        "        df\n",
        "        .filter(pl.col('period') != 'OFF')\n",
        "        .pipe(da.agg_group, 'day')\n",
        "    )\n",
        "    by_day_off = (\n",
        "        df\n",
        "        .filter(pl.col('period') == 'OFF')\n",
        "        .pipe(da.agg_group, 'day')\n",
        "    )\n",
        "\n",
        "    def get(df: pl.DataFrame, prefix: str):\n",
        "        return df.select(\n",
        "            'day',\n",
        "            pl.col('avgdelay').alias(f'{prefix}_avg'),\n",
        "            pl.col('stddelay').alias(f'{prefix}_std'),\n",
        "        )\n",
        "    g_day = (\n",
        "        by_day_all.pipe(get, 'all')\n",
        "        .join(by_day_peak.pipe(get, 'peak'), on='day', how='left')\n",
        "        .join(by_day_off.pipe(get, 'off'), on='day', how='left')\n",
        "    )\n",
        "\n",
        "    # 3. Over day by hour\n",
        "    by_hour = df.pipe(da.agg_group, 'day', 'hour')\n",
        "    return g_day, by_hour, by_hour.pipe(pivot_day)\n",
        "\n",
        "\n",
        "network_by_day, by_hour, by_hour_pivot = by_day(aggregated)\n",
        "\n",
        "# TODO: Select route\n",
        "# 4. Time series graph of route by hour by day\n",
        "\n",
        "\n",
        "highest_delay_stops = (\n",
        "    mean_stop\n",
        "    .group_by('stopid')\n",
        "    .agg(pl.col('avgdelay').max())\n",
        "    .sort('avgdelay', descending=True)\n",
        "    .select('stopid')\n",
        "    .head(100)\n",
        "    .unique()\n",
        "    .join(aggregated, on='stopid')\n",
        ")\n",
        "routes_on_highest_delay_stops = (\n",
        "    highest_delay_stops\n",
        "    .select('routeid')\n",
        "    .unique()\n",
        "    .join(aggregated, on='routeid')\n",
        ")\n",
        "agg_routes_on_highest_delay = (\n",
        "    routes_on_highest_delay_stops\n",
        "    .pipe(da.agg_group, 'routeid')\n",
        "    .drop('lastupdate')\n",
        ")\n",
        "\n",
        "\n",
        "def plot_cols(df: pl.DataFrame, key: str):\n",
        "    tidy = df.melt(id_vars=key).sort(key)\n",
        "    xticks = tidy[key]\n",
        "    ax = sb.barplot(\n",
        "        data=tidy,\n",
        "        x=key,\n",
        "        y='value',\n",
        "        hue='variable',\n",
        "        width=1,\n",
        "        order=xticks,\n",
        "    )\n",
        "    return tidy, ax\n",
        "\n",
        "\n",
        "def plot_by_route(df: pl.DataFrame):\n",
        "    tidy, ax = plot_cols(df, 'routeid')\n",
        "    xticks_unique = tidy['routeid'].unique()\n",
        "    ax.set_xticks(ax.get_xticks(), xticks_unique, rotation=90)\n",
        "\n",
        "\n",
        "# 5. Mapping delay propagations within a route\n",
        "# 6. TODO\n",
        "\n",
        "def plot_stop_and_route(df: pl.DataFrame, stop: str, route: str):\n",
        "    days = pl.DataFrame({\n",
        "        \"day\": [*range(1, 6)],\n",
        "        \"letter\": ['M', 'T', 'W', 'R', 'F'],\n",
        "    }, schema={\"day\": pl.Int8, 'letter': pl.Categorical})\n",
        "    by_day_by_hour_for_stop = (\n",
        "        da.select_stop_and_route(df, stop, route)\n",
        "        .join(days, on='day')\n",
        "        .drop('day')\n",
        "        .rename({'letter': 'day'})\n",
        "    )\n",
        "\n",
        "    ax = sb.barplot(by_day_by_hour_for_stop, x='hour', y='avgdelay', hue='day')\n",
        "    ax.set_title(f'Average delay for route {route} stop {stop}')\n",
        "    return by_day_by_hour_for_stop\n",
        "\n",
        "\n",
        "# select_stop(aggregated, \"2260\")\n",
        "\n",
        "# sb.barplot(by_day_by_hour_for_stop, x='hour', y='maxdelay')\n",
        "\n",
        "\n",
        "# highest_delay_stops.select('stopid').unique()\n",
        "\n",
        "# plot_stop_and_route(aggregated, \"2260\", \"637\")\n",
        "# da.select_stop(aggregated, \"2260\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_by_stop_and_route(agg: pl.DataFrame, stopid: str, routeid: str):\n",
        "    g_day, g_hour, g_hour_pivot = (\n",
        "        agg\n",
        "        .filter(\n",
        "            (pl.col('stopid') == stopid)\n",
        "            & (pl.col('routeid') == routeid)\n",
        "        )\n",
        "        .pipe(by_day)\n",
        "    )\n",
        "\n",
        "    g_hour.drop('lastupdate').write_csv(f'{stopid}-{routeid}-by-hour.csv')\n",
        "    g_hour_pivot.write_csv(f'{stopid}-{routeid}-by-hour-pivot.csv')\n",
        "    g_day.write_csv(f'{stopid}-{routeid}-by-day.csv')\n",
        "    return g_day, g_hour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_, bd = aggregated.pipe(filter_by_stop_and_route, '2260', '004')\n",
        "_, bd = aggregated.pipe(filter_by_stop_and_route, '2260', '637')\n",
        "m637 = aggregated.filter(\n",
        "    pl.col('routeid').__eq__('637').and_(\n",
        "        pl.col('stopid').__eq__('2260')\n",
        "    )\n",
        ")['meandelay'].mean()\n",
        "\n",
        "m004 = aggregated.filter(\n",
        "    pl.col('routeid').__eq__('004').and_(\n",
        "        pl.col('stopid').__eq__('2260')\n",
        "    )\n",
        ")['meandelay'].mean()\n",
        "m637, m004"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_dfs = da.load_raw_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_dfs.filter(\n",
        "    pl.col('routeid').__eq__('637').and_(\n",
        "        pl.col('stopid').__eq__('2260')\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "aggregated.filter((pl.col('stopid') == \"2260\")\n",
        "                  & (pl.col('routeid') == \"637\")\n",
        "                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "*_, network_pivot = aggregated.pipe(by_day)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "aggregated.filter(pl.col('stopid') == '1899').group_by('routeid').agg(\n",
        "    pl.col('meandelay').mean().alias('avgdelay'),\n",
        "    pl.col('maxdelay').max().alias('maxdelay'),\n",
        "    pl.col('count').sum()\n",
        ").write_csv('1899-by-route.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean_stop.pipe(da.add_coords, stops).drop(\n",
        "    'lastupdate').write_csv('mean-stop.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "network_by_day.drop('lastupdate').write_csv('network-by-day.csv')\n",
        "by_hour.drop('lastupdate').write_csv('network-by-day-by-hour.csv')\n",
        "# by_hour.drop('lastupdate')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# plot_cols(df, 'day') and None\n",
        "\n",
        "# plot_cols(by_hour.select('hour', 'day', 'avgdelay'), 'hour') and None\n",
        "\n",
        "# by_hour\n",
        "\n",
        "to_plot = by_hour.select('day', 'hour', 'avgdelay')\n",
        "ax = sb.lineplot(to_plot, x='hour', y='avgdelay', hue='day')\n",
        "ax.set_xticks([*range(5, 23)]) and None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "    mean_stop.drop('lastupdate')\n",
        "    .pipe(da.add_coords, stops)\n",
        "    .write_csv('mean-stop.csv')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(mean_stop) - len(mean_stop.filter(pl.col('numtrips') > 200))\n",
        "# len(mean_stop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "by_hour"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Some exploration of the `trips.json` file which DOES contain coordinates of the\n",
        "trip\n",
        "\n",
        "From initial observation of the data, each trip may have a unique path, even for\n",
        "the same route (e.g. shorter route for off-peak hours, my bus route home was\n",
        "like that at one point)\n",
        "\n",
        "Other assumptions:\n",
        "\n",
        "- There is only one type of geometry line: MultiLineString\n",
        "- The actual coordinates are wrapped inside another JSON array\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trips = da.load_trips_df()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pl.Config.set_fmt_str_lengths(1000)\n",
        "trips.sort('route_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import geopolars as gp\n",
        "gp.GeoDataFrame(mean_stop.pipe(da.add_coords, stops)).plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "How many counts should we deem useful for visualization of data?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pl.Config.set_fmt_table_cell_list_len(100)\n",
        "aggregated['routeid']\n",
        "# 1_250_916"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot_stop_and_route(aggregated, '1899', '560')\n",
        "# plot_stop_and_route(aggregated, '1899', '413')\n",
        "# plot_stop_and_route(aggregated, '5281', '002')\n",
        "# plot_stop_and_route(aggregated, '5281', '004')\n",
        "\n",
        "aggregated.filter(\n",
        "    (pl.col('stopid') == '2260')\n",
        "    # & (pl.col('routeid') == '904')\n",
        ").group_by('routeid').agg(\n",
        "    pl.col('count').sum(),\n",
        "    pl.col('meandelay').sum(),\n",
        ")\n",
        "# 25529677\n",
        "\n",
        "da.select_stop(aggregated, '2260')\n",
        "\n",
        "# plot_stop_and_route(aggregated, '2260', '004')\n",
        "plot_stop_and_route(aggregated, '2260', '637')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shapes = da.trips.load_parsed_shapes_df()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trips = da.trips.load_trips_without_shapes_df()\n",
        "shapes = da.trips.load_str_shapes_df()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "25536739"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trips.filter(pl.col('trip_id') == 25536739).join(\n",
        "    shapes,\n",
        "    on='shape_id'\n",
        ").select('route_id', 'shape_id').unique().join(\n",
        "    shapes, on='shape_id'\n",
        ").write_csv(f'004-{25536739}-shapes.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find trip with highest delay on Tuesday for route 560\n",
        "aggregated.filter(\n",
        "    (pl.col('routeid') == \"560\")\n",
        "    & (pl.col('day') == 2)\n",
        ").group_by('id').agg(\n",
        "    pl.col('meandelay').max()\n",
        ").sort('meandelay', descending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find all points for that trip\n",
        "def filter_by_trip(id: int, day: int):\n",
        "    df = aggregated.filter(\n",
        "        (pl.col('id') == id) &\n",
        "        (pl.col('day') == day)\n",
        "    ).pipe(da.add_coords, stops).sort('meandelay').drop('delay')\n",
        "    df.write_csv(f'{id}-{day}-stops.csv')\n",
        "    return df\n",
        "\n",
        "\n",
        "# filter_by_trip(25527827, 2)\n",
        "# filter_by_trip(25527777, 2)\n",
        "# filter_by_trip(25527796, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "most_delayed_trips = [*aggregated.filter(pl.col('routeid') == \"637\").group_by('id', 'date', 'day').agg(\n",
        "    pl.col('meandelay').max(),\n",
        ").sort('meandelay', descending=True).head(3).select('id', 'day').iter_rows()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "most_delayed_trips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tr = trips.filter(pl.col('shape_id') == \"004-168-West\").join(\n",
        "#     shapes, on='shape_id'\n",
        "# ).explode('geometry_line').with_columns(\n",
        "#     pl.col('geometry_line').struct.field('lon'),\n",
        "#     pl.col('geometry_line').struct.field('lat')\n",
        "# )\n",
        "\n",
        "pl.Config.set_fmt_str_lengths(100)\n",
        "\n",
        "(\n",
        "    aggregated.join(\n",
        "        trips.filter(pl.col('shape_id') ==\n",
        "                     \"004-168-West\").select(id='trip_id'),\n",
        "        on='id'\n",
        "    )\n",
        "    .with_columns(pl.col('stopid').cast(pl.Utf8))\n",
        "    .join(\n",
        "        stops,\n",
        "        left_on=\"stopid\",\n",
        "        right_on=\"stop_id\"\n",
        "    )\n",
        "    .with_columns(\n",
        "        pl.col('geometry_point')\n",
        "        .str.strip_prefix(\"POINT (\")\n",
        "        .str.strip_suffix(\")\")\n",
        "        .str.split(\" \")\n",
        "        .list.eval(pl.element().cast(pl.Float64))\n",
        "        .list.to_struct(fields=[\"lon\", \"lat\"])\n",
        "    ).with_columns(\n",
        "        pl.col('geometry_point').struct.field('lon'),\n",
        "        pl.col('geometry_point').struct.field('lat')\n",
        "    )\n",
        "    .join(tr, left_on='id', right_on=\"trip_id\")\n",
        "    .with_columns(\n",
        "        pl.col('lon')\n",
        "        .sub(pl.col('lon_right'))\n",
        "        .abs()\n",
        "        .add(pl.col('lat').sub(pl.col('lat_right')).abs())\n",
        "        .alias('manhattan')\n",
        "    )\n",
        "    .filter(pl.col('manhattan') == pl.col('manhattan').min().over('stopid'))\n",
        "    # .sort('id')\n",
        "    # .filter()\n",
        ")\n",
        "\n",
        "# tr\n",
        "# tr['geometry_line'].struct.fields"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "aggregated.join(\n",
        "    trips.filter(pl.col('shape_id') == \"004-168-West\").select(id='trip_id'),\n",
        "    on='id'\n",
        ").group_by('stopid').all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rev_1 = (\n",
        "    aggregated.join(\n",
        "        trips.select('trip_headsign', 'route_id', id='trip_id'),\n",
        "        on='id',\n",
        "    )\n",
        "    .group_by('route_id', 'trip_headsign').agg(\n",
        "        pl.col('meandelay').mean(),\n",
        "        pl.col('count').sum(),\n",
        "        pl.col('id').n_unique()\n",
        "    )\n",
        "    .sort('meandelay', descending=True)\n",
        "    # .write_csv('avg-delay-by-trip-headsign.csv')\n",
        ")\n",
        "\"\"\"\n",
        "1. Join `trips` to `aggregated` to new dataframe, only adding `trip_headsign` column. \n",
        "\n",
        " *THEN* GroupBy(`trip_headsign`) + Aggregate(average the delay). \n",
        "Drop all columns except the Heading, Aggregated Average Delay\n",
        "\n",
        "-> Sort by descending meandelay\n",
        "\"\"\"\n",
        "\n",
        "max_trip_headsign = rev_1.filter(pl.col('id') > 30)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rev_2_1 = (\n",
        "    aggregated.join(\n",
        "        trips.select('trip_headsign', 'route_id', id='trip_id'),\n",
        "        on='id',\n",
        "    )\n",
        "    .filter(\n",
        "        (pl.col('routeid') == max_trip_headsign['route_id'][0]) &\n",
        "        (pl.col('trip_headsign') == max_trip_headsign['trip_headsign'][0])\n",
        "    )\n",
        "    .group_by('id')\n",
        "    .agg(\n",
        "        pl.col('route_id').first(),\n",
        "        pl.col('trip_headsign').first(),\n",
        "        pl.col('meandelay').mean(),\n",
        "        pl.col('count').sum(),\n",
        "    )\n",
        "    .sort('meandelay', 'route_id', descending=True)\n",
        "    # .write_csv('avg-by-trip-id-508-Meadows.csv')\n",
        ")\n",
        "\"\"\"\n",
        "2.1 Based on a given **Heading**: Select all associated rows, GroupBy(TripId) + \n",
        "Aggregate(Average the delay). \n",
        "-> Sort by descending meandelay. Select highest meandelay of the few. \n",
        "(tripid is the identifier)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def join_stops(df: pl.DataFrame, stops: pl.DataFrame):\n",
        "    return (\n",
        "        df.with_columns(pl.col('stopid').cast(pl.Utf8))\n",
        "        .join(stops, left_on='stopid', right_on='stop_id')\n",
        "    )\n",
        "\n",
        "\n",
        "def make_sequence(\n",
        "    df: pl.DataFrame,\n",
        "    trip_id: int | None = None,\n",
        "    shape_id: str | None = None,\n",
        "):\n",
        "    trips = da.trips.load_trips_without_shapes_df()\n",
        "    shapes = da.trips.load_parsed_shapes_df()\n",
        "    by_stop = df.group_by('stopid').agg(\n",
        "        pl.col('meandelay').mean(),\n",
        "        pl.col('stop_lon').first(),\n",
        "        pl.col('stop_lat').first(),\n",
        "        pl.col('routeid').first().cast(pl.Utf8),\n",
        "    )\n",
        "    pred = (\n",
        "        pl.col('trip_id').eq(trip_id) if trip_id\n",
        "        else pl.col('shape_id').eq(shape_id) if shape_id\n",
        "        else True)\n",
        "    trip_points = (\n",
        "        trips\n",
        "        .filter(pred)\n",
        "        .join(shapes, on='shape_id')\n",
        "        .unique('shape_id')\n",
        "        .explode('geometry_line')\n",
        "        .unique('geometry_line', keep='first')\n",
        "        .with_row_index()\n",
        "    )\n",
        "    return (\n",
        "        trip_points.join(\n",
        "            by_stop,\n",
        "            left_on='route_id',\n",
        "            right_on='routeid',\n",
        "        )\n",
        "        .with_columns(\n",
        "            pl.col('geometry_line').struct.field(\n",
        "                'lon').sub(pl.col('stop_lon')),\n",
        "            pl.col('geometry_line').struct.field(\n",
        "                'lat').sub(pl.col('stop_lat')),\n",
        "        )\n",
        "        # Get euclidean distance\n",
        "        .with_columns(\n",
        "            pl.col('lon').pow(2).add(\n",
        "                pl.col('lat').pow(2)).sqrt().alias('euclidean')\n",
        "        )\n",
        "        # Get the minimum euclidean distance for a stop\n",
        "        .filter(pl.col('euclidean').eq(pl.col('euclidean').min().over('stopid')))\n",
        "        # Re-create index\n",
        "        .sort('index')\n",
        "        .drop('index')\n",
        "        .with_row_index()\n",
        "        .select([\n",
        "            'index',\n",
        "            'route_id',\n",
        "            'trip_headsign',\n",
        "            'stopid',\n",
        "            'meandelay',\n",
        "            'stop_lon',\n",
        "            'stop_lat',\n",
        "        ])\n",
        "    )\n",
        "\n",
        "\n",
        "selected_trip = 25536592\n",
        "agg_points = (\n",
        "    aggregated\n",
        "    .filter(pl.col('id').eq(selected_trip))\n",
        "    .pipe(join_stops, stops)\n",
        ")\n",
        "rev_2_2 = make_sequence(agg_points, trip_id=selected_trip)\n",
        "\"\"\"\n",
        "2.2 Based on the selected `trip_headsign` **AND** `trip_id`: Select all the \n",
        "associated rows, join co-ordinates to StopId, join sequence #\n",
        "\"\"\"\n",
        "# rev_2_2.write_csv(f'rev-2.2-508-meadows-{selected_trip}-stops.csv')\n",
        "\n",
        "\n",
        "selected_shape = \"508-1-East\"\n",
        "agg_points = (\n",
        "    aggregated\n",
        "    .join((trips\n",
        "           .filter(pl.col('shape_id').eq(selected_shape))\n",
        "           .select('trip_id', 'shape_id')\n",
        "           ),\n",
        "          left_on='id',\n",
        "          right_on='trip_id'\n",
        "          )\n",
        "    .pipe(join_stops, stops)\n",
        ")\n",
        "rev_2_3 = make_sequence(agg_points, shape_id=selected_shape)\n",
        "\"\"\"\n",
        "2.3 Based on the selected **Heading**: Select all the associated rows, \n",
        "GroupBy(Sequence #) + Aggregate(Average the delay) \n",
        "\n",
        "-> Output df: **Sequence # | AverageAverageDelay**\n",
        "\"\"\"\n",
        "# rev_2_3.write_csv(f'rev-2.3-{selected_shape}-stops.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# trips.filter(pl.col('trip_headsign').eq('508 Meadows'))['shape_id'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# trips['shape_id'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trips.write_csv('trips-new.csv')\n",
        "shapes.write_csv('shapes-new.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "aggregated.filter(pl.col('id') == 25536770).sort('lastupdate')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for trip_id, day in most_delayed_trips:\n",
        "    filter_by_trip(trip_id, day)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_dfs = da.load_raw_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# mean_stop.filter(pl.col('count') > 20).sort('avgdelay', descending=True)\n",
        "\n",
        "# pl.Config\n",
        "\n",
        "more_than_one_route = (\n",
        "    aggregated\n",
        "    .group_by('stopid')\n",
        "    .agg(pl.col('routeid').unique())\n",
        "    .with_columns(pl.col('routeid').list.len())\n",
        "    .filter(pl.col('routeid') > 1)\n",
        "    .select('stopid')\n",
        ")\n",
        "\n",
        "# aggregated.join(more_than_one_route, on='stopid')\n",
        "mean_stop.join(more_than_one_route, on='stopid').sort(\n",
        "    'avgdelay', descending=True)\n",
        "\n",
        "(\n",
        "    aggregated.filter(pl.col('stopid') == \"2260\")\n",
        "    ['routeid'].unique()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trips.filter(pl.col('route_id') == \"004\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
