{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import seaborn as sb\n",
    "import gtfs_delay_analysis as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = pl.read_csv(\n",
    "    '/home/chrlz/dox/dl/ETS_Bus_Schedule_GTFS_Data_Feed_-_Stops_20240216.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated = da.load_aggregate_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we know that all trip id is unique for a single day, no need to worry about overlaps\n",
    "\n",
    "Average delay in a stop every 3 minutes 10 recordings of a bus\n",
    "\n",
    "AM: 7am-9am\n",
    "PM: 4pm-7pm\n",
    "OFF: 5am-7am, 9am-4-pm, 7pm-10pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Map delay average over week\n",
    "mean_stop = aggregated.pipe(da.agg_group, 'stopid')\n",
    "\n",
    "# 2. Over week by day\n",
    "# TODO: Filter by PEAK, OFF, and DAY\n",
    "def by_day(df: pl.DataFrame):\n",
    "    by_day_all = df.pipe(da.agg_group, 'day')\n",
    "    by_day_peak = (\n",
    "        df\n",
    "        .filter(pl.col('period') != 'OFF')\n",
    "        .pipe(da.agg_group, 'day')\n",
    "    )\n",
    "    by_day_off = (\n",
    "        df\n",
    "        .filter(pl.col('period') == 'OFF')\n",
    "        .pipe(da.agg_group, 'day')\n",
    "    )\n",
    "\n",
    "    # 3. Over day by hour\n",
    "    by_hour = aggregated.pipe(da.agg_group, 'day', 'hour')\n",
    "    return by_day_all, by_day_peak, by_day_off, by_hour\n",
    "\n",
    "\n",
    "by_day_all, by_day_peak, by_day_off, by_hour = by_day(aggregated)\n",
    "\n",
    "# TODO: Select route\n",
    "# 4. Time series graph of route by hour by day\n",
    "\n",
    "\n",
    "highest_delay_stops = (\n",
    "    mean_stop\n",
    "    .group_by('stopid')\n",
    "    .agg(pl.col('avgdelay').max())\n",
    "    .sort('avgdelay', descending=True)\n",
    "    .select('stopid')\n",
    "    .head(100)\n",
    "    .unique()\n",
    "    .join(aggregated, on='stopid')\n",
    ")\n",
    "routes_on_highest_delay_stops = (\n",
    "    highest_delay_stops\n",
    "    .select('routeid')\n",
    "    .unique()\n",
    "    .join(aggregated, on='routeid')\n",
    ")\n",
    "agg_routes_on_highest_delay = (\n",
    "    routes_on_highest_delay_stops\n",
    "    .pipe(da.agg_group, 'routeid')\n",
    "    .drop('lastupdate')\n",
    ")\n",
    "\n",
    "\n",
    "def plot_cols(df: pl.DataFrame, key: str):\n",
    "    tidy = df.melt(id_vars=key).sort(key)\n",
    "    xticks = tidy[key]\n",
    "    ax = sb.barplot(\n",
    "        data=tidy,\n",
    "        x=key,\n",
    "        y='value',\n",
    "        hue='variable',\n",
    "        width=1,\n",
    "        order=xticks,\n",
    "    )\n",
    "    return tidy, ax\n",
    "\n",
    "\n",
    "def plot_by_route(df: pl.DataFrame):\n",
    "    tidy, ax = plot_cols(df, 'routeid')\n",
    "    xticks_unique = tidy['routeid'].unique()\n",
    "    ax.set_xticks(ax.get_xticks(), xticks_unique, rotation=90)\n",
    "\n",
    "\n",
    "# 5. Mapping delay propagations within a route\n",
    "# 6. TODO\n",
    "\n",
    "def plot_stop_and_route(df: pl.DataFrame, stop: str, route: str):\n",
    "    days = pl.DataFrame({\n",
    "        \"day\": [*range(1, 6)],\n",
    "        \"letter\": ['M', 'T', 'W', 'R', 'F'],\n",
    "    }, schema={\"day\": pl.Int8, 'letter': pl.Categorical})\n",
    "    by_day_by_hour_for_stop = (\n",
    "        da.select_stop_and_route(df, stop, route)\n",
    "        .join(days, on='day')\n",
    "        .drop('day')\n",
    "        .rename({'letter': 'day'})\n",
    "    )\n",
    "\n",
    "    ax = sb.barplot(by_day_by_hour_for_stop, x='hour', y='avgdelay', hue='day')\n",
    "    ax.set_title(f'Average delay for route {route} stop {stop}')\n",
    "    return by_day_by_hour_for_stop\n",
    "\n",
    "\n",
    "# select_stop(aggregated, \"2260\")\n",
    "\n",
    "# sb.barplot(by_day_by_hour_for_stop, x='hour', y='maxdelay')\n",
    "\n",
    "\n",
    "# highest_delay_stops.select('stopid').unique()\n",
    "\n",
    "# plot_stop_and_route(aggregated, \"2260\", \"637\")\n",
    "# da.select_stop(aggregated, \"2260\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_all_1899_560, by_peak_1899_560, by_off_1899_560, by_hour_1899_560= by_day(aggregated.filter(\n",
    "    (pl.col('stopid')=='1899') \n",
    "    & (pl.col('routeid') == '560')\n",
    "))\n",
    "df_1899_560 = by_all_1899_560.select('day', all_avg=pl.col('avgdelay'), all_max=pl.col('maxdelay'), ).join(\n",
    "    by_peak_1899_560.select('day', peak_avg=pl.col('avgdelay'), peak_max=pl.col('maxdelay'), ), on='day'\n",
    ").join(\n",
    "    by_off_1899_560.select('day', off_avg=pl.col('avgdelay'), off_max=pl.col('maxdelay'), ), on='day'\n",
    ")\n",
    "by_hour_1899_560.drop('lastupdate').write_csv('1899-560-by-hour.csv')\n",
    "df_1899_560.write_csv('1899-560-by-day.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_hour_1899_560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated.filter(pl.col('stopid')=='1899').group_by('routeid').agg(\n",
    "    pl.col('meandelay').mean().alias('avgdelay'),\n",
    "    pl.col('maxdelay').max().alias('maxdelay'),\n",
    "    pl.col('count').sum()\n",
    ").write_csv('1899-by-route.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_stop.pipe(da.add_coords, stops).drop('lastupdate').write_csv('mean-stop.csv')\n",
    "\n",
    "df = by_day_all.select('day', all_avg=pl.col('avgdelay'), all_max=pl.col('maxdelay'), ).join(\n",
    "    by_day_peak.select('day', peak_avg=pl.col('avgdelay'), peak_max=pl.col('maxdelay'), ), on='day'\n",
    ").join(\n",
    "    by_day_off.select('day', off_avg=pl.col('avgdelay'), off_max=pl.col('maxdelay'), ), on='day'\n",
    ")\n",
    "\n",
    "df.write_csv('network-by-day.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_hour.drop('lastupdate').write_csv('network-by-day-by-hour.csv')\n",
    "# by_hour.drop('lastupdate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot_cols(df, 'day') and None\n",
    "\n",
    "# plot_cols(by_hour.select('hour', 'day', 'avgdelay'), 'hour') and None\n",
    "\n",
    "# by_hour\n",
    "\n",
    "to_plot = by_hour.select('day', 'hour', 'avgdelay')\n",
    "ax = sb.lineplot(to_plot, x='hour', y='avgdelay', hue='day')\n",
    "ax.set_xticks([*range(5, 23)]) and None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    mean_stop.drop('lastupdate')\n",
    "    .pipe(da.add_coords, stops)\n",
    "    .write_csv('mean-stop.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mean_stop) - len(mean_stop.filter(pl.col('numtrips') > 200))\n",
    "# len(mean_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some exploration of the `trips.json` file which DOES contain coordinates of the\n",
    "trip\n",
    "\n",
    "From initial observation of the data, each trip may have a unique path, even for\n",
    "the same route (e.g. shorter route for off-peak hours, my bus route home was\n",
    "like that at one point)\n",
    "\n",
    "Other assumptions:\n",
    "- There is only one type of geometry line: MultiLineString\n",
    "- The actual coordinates are wrapped inside another JSON array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = da.load_trips_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set_fmt_str_lengths(1000)\n",
    "trips.sort('route_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopolars as gp\n",
    "gp.GeoDataFrame(mean_stop.pipe(da.add_coords, stops)).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many counts should we deem useful for visualization of data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set_fmt_table_cell_list_len(100)\n",
    "aggregated['routeid']\n",
    "# 1_250_916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# da.select_stop(aggregated, '5281')\n",
    "# plot_stop_and_route(aggregated, '1899', '560')\n",
    "# plot_stop_and_route(aggregated, '1899', '413')\n",
    "# plot_stop_and_route(aggregated, '5281', '002')\n",
    "# plot_stop_and_route(aggregated, '5281', '004')\n",
    "# plot_stop_and_route(aggregated, '5281', '904')\n",
    "\n",
    "aggregated.filter(\n",
    "    (pl.col('stopid') == '5281') \n",
    "    # & (pl.col('routeid') == '904')\n",
    ").group_by('routeid').agg(\n",
    "    pl.col('count').sum(),\n",
    "    pl.col('meandelay').sum(),\n",
    ")\n",
    "# 25529677"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = da.trips.load_parsed_shapes_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = da.trips.load_trips_without_shapes_df()\n",
    "shapes = da.trips.load_str_shapes_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.filter(pl.col('route_id') ==\"560\") .join(\n",
    "    shapes, \n",
    "    on='shape_id'\n",
    ").select('route_id', 'shape_id').unique().join(\n",
    "    shapes, on='shape_id'\n",
    ").write_csv('560-shapes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find trip with highest delay on Tuesday for route 560\n",
    "aggregated.filter(\n",
    "    (pl.col('routeid') == \"560\")\n",
    "    & (pl.col('day') == 2)\n",
    ").group_by('id').agg(\n",
    "    pl.col('meandelay').max()\n",
    ").sort('meandelay', descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all points for that trip\n",
    "def filter_by_trip(id: int, day:int):\n",
    "    df= aggregated.filter(\n",
    "        (pl.col('id') == id) & \n",
    "        (pl.col('day') == day)\n",
    "    ).pipe(da.add_coords, stops).sort('meandelay').drop('delay')\n",
    "    df.write_csv(f'{id}-{day}-stops.csv')\n",
    "    return df\n",
    "filter_by_trip(25527827, 2)\n",
    "filter_by_trip(25527777, 2)\n",
    "filter_by_trip(25527796, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dfs = da.load_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
